{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from members import Members\n",
    "\n",
    "member = Members().get_data()\n",
    "member = Members().clean_data(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather import Weather\n",
    "\n",
    "weather = Weather().get_data()\n",
    "weather = Weather().clean_data(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peaks import Peaks\n",
    "\n",
    "peak = Peaks().get_data()\n",
    "peak = Peaks().clean_data(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expeds import Expeds\n",
    "\n",
    "exped = Expeds().get_data()\n",
    "exped = Expeds().clean_data(exped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member (16383, 47)\n",
      "peak (468, 18)\n",
      "exped (3704, 57)\n"
     ]
    }
   ],
   "source": [
    "print('member', member.shape)\n",
    "print('peak', peak.shape)\n",
    "print('exped', exped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_to_drop = ['memb_id',\n",
    "               'year',\n",
    "               'unique_id',\n",
    "                 'peak_id',\n",
    "                 'residence',\n",
    "                 'occupation',\n",
    "                 'summit_claimed',\n",
    "                 'summit_disputed',\n",
    "                 'highpt',\n",
    "                 'high_point',\n",
    "                 'death',\n",
    "                 'death_type',\n",
    "                 'death_height',\n",
    "                 'death_class',\n",
    "                 'summit_bid',\n",
    "                 'summit_term',\n",
    "               'summit_date1',\n",
    "               'citizenship'\n",
    "                ]\n",
    "\n",
    "member.drop(columns= mem_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_to_drop = ['peak_name',\n",
    "                 'pk_name_2',\n",
    "                 'location',\n",
    "                 'himal',\n",
    "                 'region',\n",
    "                 'open',\n",
    "                 'unlisted',\n",
    "                 'trekking',\n",
    "                 'restrict',\n",
    "                 'country_status',\n",
    "                 'year',\n",
    "                 'season',\n",
    "                 'expid',\n",
    "                 'summiter_country',\n",
    "                 'summiters'\n",
    "                ]\n",
    "\n",
    "peak.drop(columns= peak_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_to_drop = ['year',\n",
    "                 'season',\n",
    "                 'route1',\n",
    "                 'route2',\n",
    "                 'nation',\n",
    "                 'leaders',\n",
    "                 'sponsor',\n",
    "                 'success1',\n",
    "                 'success2',\n",
    "                 'ascent1',\n",
    "                 'ascent2',\n",
    "                 'claimed',\n",
    "                 'disputed',\n",
    "                 'countries',\n",
    "               'summit_time',\n",
    "               'term_date',\n",
    "               'term_reason',\n",
    "               'term_note',\n",
    "               'high_point',\n",
    "               'traverse',\n",
    "               'ski',\n",
    "               'parapente',\n",
    "               'o2_climb',\n",
    "               'o2_descent',\n",
    "               'o2_sleep',\n",
    "               'o2_medical',\n",
    "               'o2_taken',\n",
    "               'o2_unkwn',\n",
    "               'o2_used',\n",
    "               'o2_none',\n",
    "               'other_smts',\n",
    "               'campsites',\n",
    "               'accidents',\n",
    "               'achievment',\n",
    "               'agency',\n",
    "               'peak_name',\n",
    "               'primmem',\n",
    "               'summiter_deaths',\n",
    "               'summit_members',\n",
    "               'summit_hired',\n",
    "               'hired_deaths'\n",
    "                ]\n",
    "\n",
    "exped.drop(columns= exp_to_drop, inplace=True)\n",
    "exped['summit_date'] = pd.to_datetime(exped.summit_date, errors = 'coerce')\n",
    "exped['bc_date'] = pd.to_datetime(exped.bc_date , errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exped.merge(member, on='exp_id', how = 'right')\n",
    "\n",
    "df = df.set_index('summit_date')\n",
    "wet = weather.set_index('date_time')\n",
    "\n",
    "df = df.merge(wet, how='left', left_index=True, right_index=True)\n",
    "\n",
    "df = df.reset_index()\n",
    "df.drop(columns=['exp_id', 'index', 'bc_date', 'moonrise', 'moonset', 'sunrise', 'sunset'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16383 entries, 0 to 16382\n",
      "Data columns (total 60 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   peak_id            16383 non-null  object \n",
      " 1   host               16383 non-null  object \n",
      " 2   summit_days        16383 non-null  int64  \n",
      " 3   tot_days           16383 non-null  int64  \n",
      " 4   camps              16383 non-null  int64  \n",
      " 5   rope               16383 non-null  int64  \n",
      " 6   tot_members        16383 non-null  int64  \n",
      " 7   tot_hired          16383 non-null  int64  \n",
      " 8   no_hired           16383 non-null  bool   \n",
      " 9   comrte             16383 non-null  bool   \n",
      " 10  stdrte             16383 non-null  bool   \n",
      " 11  primrte            16383 non-null  bool   \n",
      " 12  peak_height        16383 non-null  int64  \n",
      " 13  season             16383 non-null  object \n",
      " 14  sex_M              16383 non-null  float64\n",
      " 15  yob                16383 non-null  float64\n",
      " 16  status             16383 non-null  object \n",
      " 17  leader             16383 non-null  bool   \n",
      " 18  deputy             16383 non-null  bool   \n",
      " 19  bconly             16383 non-null  bool   \n",
      " 20  nottobc            16383 non-null  bool   \n",
      " 21  support            16383 non-null  bool   \n",
      " 22  disabled           16383 non-null  bool   \n",
      " 23  hired              16383 non-null  bool   \n",
      " 24  sherpa             16383 non-null  bool   \n",
      " 25  tibetan            16383 non-null  bool   \n",
      " 26  summit_success     16383 non-null  bool   \n",
      " 27  solo               16383 non-null  bool   \n",
      " 28  traverse           16383 non-null  bool   \n",
      " 29  ski                16383 non-null  bool   \n",
      " 30  parapente          16383 non-null  bool   \n",
      " 31  speed              16383 non-null  bool   \n",
      " 32  route1             16383 non-null  int64  \n",
      " 33  ascent1            16383 non-null  int64  \n",
      " 34  o2_used            16383 non-null  bool   \n",
      " 35  o2_none            16383 non-null  bool   \n",
      " 36  o2_climb           16383 non-null  bool   \n",
      " 37  o2_descent         16383 non-null  bool   \n",
      " 38  o2_sleep           16383 non-null  bool   \n",
      " 39  o2_medical         16383 non-null  bool   \n",
      " 40  age                16383 non-null  float64\n",
      " 41  maxtempC           15219 non-null  float64\n",
      " 42  mintempC           15219 non-null  float64\n",
      " 43  totalSnow_cm       15219 non-null  float64\n",
      " 44  sunHour            15219 non-null  float64\n",
      " 45  uvIndex            15219 non-null  float64\n",
      " 46  moon_illumination  15219 non-null  float64\n",
      " 47  DewPointC          15219 non-null  float64\n",
      " 48  FeelsLikeC         15219 non-null  float64\n",
      " 49  HeatIndexC         15219 non-null  float64\n",
      " 50  WindChillC         15219 non-null  float64\n",
      " 51  WindGustKmph       15219 non-null  float64\n",
      " 52  cloudcover         15219 non-null  float64\n",
      " 53  humidity           15219 non-null  float64\n",
      " 54  precipMM           15219 non-null  float64\n",
      " 55  pressure           15219 non-null  float64\n",
      " 56  tempC              15219 non-null  float64\n",
      " 57  visibility         15219 non-null  float64\n",
      " 58  winddirDegree      15219 non-null  float64\n",
      " 59  windspeedKmph      15219 non-null  float64\n",
      "dtypes: bool(25), float64(22), int64(9), object(4)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = []\n",
    "col_bool =[]\n",
    "col_object =[]\n",
    "\n",
    "for col in df:\n",
    "    if df[col].dtype == \"float64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == \"int64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'bool':\n",
    "        col_bool.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'object':\n",
    "        col_object.append(col)\n",
    "        \n",
    "col_bool.remove('summit_success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:        \n",
    "    if df[col].dtype == 'bool':\n",
    "        df[col].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=2)),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop= 'first', handle_unknown='error'))])\n",
    "\n",
    "# boolean_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, col_num),\n",
    "        ('cat', categorical_transformer, col_object)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X = df.drop(columns=['summit_success'])\n",
    "y = df.summit_success\n",
    "\n",
    "X_trans = clf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.801\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"model score: %.3f\" % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.79      0.82      2790\n",
      "        True       0.75      0.81      0.78      2125\n",
      "\n",
      "    accuracy                           0.80      4915\n",
      "   macro avg       0.80      0.80      0.80      4915\n",
      "weighted avg       0.80      0.80      0.80      4915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      1.00      0.72      2790\n",
      "        True       0.00      0.00      0.00      2125\n",
      "\n",
      "    accuracy                           0.57      4915\n",
      "   macro avg       0.28      0.50      0.36      4915\n",
      "weighted avg       0.32      0.57      0.41      4915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Baseline\n",
    "y_base = np.zeros(len(y_test))\n",
    "print(classification_report(y_test, y_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
