{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from members import Members\n",
    "from weather import Weather\n",
    "from expeds import Expeds\n",
    "\n",
    "\n",
    "# Get Data\n",
    "member = Members().get_data()\n",
    "member = Members().clean_data(member)\n",
    "\n",
    "weather = Weather().get_data()\n",
    "weather = Weather().clean_data(weather)\n",
    "\n",
    "exped = Expeds().get_data()\n",
    "exped = Expeds().clean_data(exped)\n",
    "\n",
    "# Drop columns\n",
    "mem_to_drop = ['memb_id','year','unique_id','peak_id','residence','occupation',\n",
    "'summit_claimed','summit_disputed','highpt','high_point','death','death_type',\n",
    "'death_height','death_class','summit_bid','summit_term','summit_date1',\n",
    "'citizenship','o2_climb','o2_descent','o2_sleep','o2_medical', 'o2_none', \n",
    "'yob', 'route1', 'ascent1', 'leader', 'deputy', 'bconly', 'nottobc', 'support', \n",
    "'hired', 'sherpa', 'tibetan']\n",
    "\n",
    "\n",
    "exp_to_drop = ['year','season','route1','route2','nation','leaders',\n",
    "'sponsor','success1','success2', 'ascent1','claimed','disputed',\n",
    "'countries','summit_time','term_date','term_note','high_point',\n",
    "'traverse','ski','parapente','o2_climb','o2_descent','o2_sleep',\n",
    "'o2_medical','o2_taken','o2_unkwn','o2_used','o2_none','other_smts',\n",
    "'campsites','accidents','achievment','agency','peak_name','primmem',\n",
    "'summiter_deaths','summit_members','summit_hired','hired_deaths']\n",
    "\n",
    "member.drop(columns= mem_to_drop, inplace=True)\n",
    "exped.drop(columns= exp_to_drop, inplace=True)\n",
    "\n",
    "exped['summit_date'] = pd.to_datetime(exped.summit_date, errors = 'coerce')\n",
    "exped['bc_date'] = pd.to_datetime(exped.bc_date , errors = 'coerce')\n",
    "exped = exped.set_index('summit_date')\n",
    "weather = weather.set_index('date_time')\n",
    "\n",
    "# Feature Engineering (1/2)\n",
    "exped['sherpa_ratio'] = exped['tot_hired'] / exped['tot_members']\n",
    "exped['sherpa_ratio'] = np.where(exped['sherpa_ratio'] == np.inf, 0, exped['sherpa_ratio'])\n",
    "\n",
    "weather['pressure_past'] = weather['pressure'].rolling(window=3).mean()\n",
    "weather['pressure_futur'] = weather['pressure'].shift(-2).rolling(window=3).mean()\n",
    "weather['stability'] = weather['pressure_futur'] - weather['pressure_past']\n",
    "\n",
    "# Merge DataFrames\n",
    "df = exped.merge(weather, how='left', left_index=True, right_index=True)\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index' : 'summit_date'})\n",
    "df = df.merge(member, on='exp_id', how = 'right')\n",
    "df.drop(columns=['moonrise', 'moonset', 'sunrise', 'sunset'], inplace = True)\n",
    "df = df.dropna(subset=['summit_date', 'bc_date'])\n",
    "\n",
    "# Feature Engineering (2/2)\n",
    "df['cumul_snow'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    date1 = row['bc_date'].date()\n",
    "    date2 = row['summit_date'].date()\n",
    "    acc_snow = weather.loc[date1:date2, 'totalSnow_cm'].sum()\n",
    "    df.loc[index, 'cumul_snow'] = acc_snow\n",
    "\n",
    "df.drop(columns=['summit_date', 'exp_id', 'bc_date', 'term_reason', 'pressure_past', 'pressure_futur'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['peak_id', 'host', 'summit_days', 'tot_days', 'camps', 'rope',\n",
       "       'tot_members', 'tot_hired', 'no_hired', 'comrte', 'stdrte', 'primrte',\n",
       "       'peak_height', 'sherpa_ratio', 'maxtempC', 'mintempC', 'totalSnow_cm',\n",
       "       'sunHour', 'uvIndex', 'moon_illumination', 'DewPointC', 'FeelsLikeC',\n",
       "       'HeatIndexC', 'WindChillC', 'WindGustKmph', 'cloudcover', 'humidity',\n",
       "       'precipMM', 'pressure', 'tempC', 'visibility', 'winddirDegree',\n",
       "       'windspeedKmph', 'stability', 'season', 'sex_M', 'status', 'disabled',\n",
       "       'summit_success', 'solo', 'traverse', 'ski', 'parapente', 'speed',\n",
       "       'o2_used', 'age', 'cumul_snow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns used for the model\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "col_num = []\n",
    "col_bool =[]\n",
    "col_object =[]\n",
    "\n",
    "for col in df:\n",
    "    if df[col].dtype == \"float64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == \"int64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'bool':\n",
    "        col_bool.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'object':\n",
    "        col_object.append(col)\n",
    "        \n",
    "col_bool.remove('summit_success')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop= 'first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, col_num),\n",
    "        ('cat', categorical_transformer, col_object)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X = df.drop(columns=['summit_success'])\n",
    "y = df.summit_success\n",
    "\n",
    "X_trans = clf.fit_transform(X)\n",
    "X_tr = X_trans.toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr, y, test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84      2290\n",
      "        True       0.79      0.82      0.81      1852\n",
      "\n",
      "    accuracy                           0.82      4142\n",
      "   macro avg       0.82      0.82      0.82      4142\n",
      "weighted avg       0.83      0.82      0.82      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Traning\n",
    "from sklearn.metrics import classification_report\n",
    "boost = XGBClassifier()\n",
    "boost.fit(X_train, y_train)\n",
    "ypred = boost.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.82      0.83      2290\n",
      "        True       0.78      0.81      0.79      1852\n",
      "\n",
      "    accuracy                           0.81      4142\n",
      "   macro avg       0.81      0.81      0.81      4142\n",
      "weighted avg       0.81      0.81      0.81      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model of Jeremy\n",
    "best_of_best = XGBClassifier(n_estimators = 300,\n",
    "                            max_depth = 18,\n",
    "                            learning_rate = 0.3,\n",
    "                            gamma = 0.8,\n",
    "                            min_child_weight = 4,\n",
    "                            colsample_bytree = 0.3\n",
    "                            )\n",
    "\n",
    "best_of_best.fit(X_train, y_train)\n",
    "ypred = best_of_best.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.76      0.75      2290\n",
      "        True       0.69      0.66      0.68      1852\n",
      "\n",
      "    accuracy                           0.72      4142\n",
      "   macro avg       0.71      0.71      0.71      4142\n",
      "weighted avg       0.72      0.72      0.72      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression(max_iter=500)\n",
    "reg.fit(X_train, y_train)\n",
    "ypred = reg.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.81      0.82      2290\n",
      "        True       0.77      0.80      0.79      1852\n",
      "\n",
      "    accuracy                           0.81      4142\n",
      "   macro avg       0.80      0.81      0.80      4142\n",
      "weighted avg       0.81      0.81      0.81      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "ypred = clf.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                   param_distributions={'booster': ['gbtree', 'gblinear'],\n",
       "                                        'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.1,\n",
       "                                                          1],\n",
       "                                        'max_depth': [5, 10, 25, 50],\n",
       "                                        'min_child_weight': [0.1, 1, 5, 10, 50],\n",
       "                                        'n_estimators': [50, 100, 250, 500],\n",
       "                                        'reg_alpha': [0.0001, 0.001, 0.1, 1],\n",
       "                                        'reg_lambda': [0.0001, 0.001, 0.1, 1],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1001, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'booster' : ['gbtree', 'gblinear'],\n",
    "        'min_child_weight': [0.1, 1, 5, 10, 50],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [5, 10, 25, 50],\n",
    "        'learning_rate': [0.0001, 0.001, 0.1, 1],\n",
    "        'n_estimators': [50, 100, 250, 500],\n",
    "        'reg_alpha': [0.0001, 0.001, 0.1, 1],\n",
    "        'reg_lambda': [0.0001, 0.001, 0.1, 1]\n",
    "        }\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(model, \n",
    "                                   cv=5,\n",
    "                                   param_distributions=params,  \n",
    "                                   scoring='accuracy', \n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1, \n",
    "                                   random_state=1001)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.001, max_delta_step=0, max_depth=25,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0.1, reg_lambda=0.0001, scale_pos_weight=1,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.81      0.84      2290\n",
      "        True       0.78      0.84      0.81      1852\n",
      "\n",
      "    accuracy                           0.82      4142\n",
      "   macro avg       0.82      0.82      0.82      4142\n",
      "weighted avg       0.83      0.82      0.82      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 25, 50],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 3, 5],\n",
       "                                        'min_samples_split': [2, 3, 5],\n",
       "                                        'n_estimators': [100, 200, 500]},\n",
       "                   random_state=1001, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'n_estimators' : [100,200,500],\n",
    "        'criterion' : ['gini', 'entropy'],\n",
    "        'min_samples_split': [2, 3, 5],\n",
    "        'max_depth': [5, 10, 25, 50],\n",
    "        'min_samples_leaf': [1, 3, 5],\n",
    "        'max_features': [\"sqrt\", \"log2\"]\n",
    "        }\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(model, \n",
    "                                   cv=5,\n",
    "                                   param_distributions=params,  \n",
    "                                   scoring='accuracy', \n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1, \n",
    "                                   random_state=1001)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=25, max_features='log2',\n",
       "                       min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.81      0.83      2290\n",
      "        True       0.78      0.83      0.80      1852\n",
      "\n",
      "    accuracy                           0.82      4142\n",
      "   macro avg       0.81      0.82      0.82      4142\n",
      "weighted avg       0.82      0.82      0.82      4142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test xgb_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from xgb_model import HimalXGB\n",
    "\n",
    "model = HimalXGB().train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6fefe5c93724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHimalXGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = HimalXGB().predict_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model without weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from members import Members\n",
    "from expeds import Expeds\n",
    "\n",
    "\n",
    "# Get Data\n",
    "member = Members().get_data()\n",
    "member = Members().clean_data(member)\n",
    "\n",
    "exped = Expeds().get_data()\n",
    "exped = Expeds().clean_data(exped)\n",
    "\n",
    "# Drop columns\n",
    "mem_to_drop = ['memb_id','year','unique_id','peak_id','residence','occupation',\n",
    "'summit_claimed','summit_disputed','highpt','high_point','death','death_type',\n",
    "'death_height','death_class','summit_bid','summit_term','summit_date1',\n",
    "'citizenship','o2_climb','o2_descent','o2_sleep','o2_medical', 'o2_none', \n",
    "'yob', 'route1', 'ascent1', 'leader', 'deputy', 'bconly', 'nottobc', 'support', \n",
    "'hired', 'sherpa', 'tibetan']\n",
    "\n",
    "\n",
    "exp_to_drop = ['year','season','route1','route2','nation','leaders',\n",
    "'sponsor','success1','success2', 'ascent1','claimed','disputed',\n",
    "'countries','summit_time','term_date','term_note','high_point',\n",
    "'traverse','ski','parapente','o2_climb','o2_descent','o2_sleep',\n",
    "'o2_medical','o2_taken','o2_unkwn','o2_used','o2_none','other_smts',\n",
    "'campsites','accidents','achievment','agency','peak_name','primmem',\n",
    "'summiter_deaths','summit_members','summit_hired','hired_deaths']\n",
    "\n",
    "member.drop(columns= mem_to_drop, inplace=True)\n",
    "exped.drop(columns= exp_to_drop, inplace=True)\n",
    "\n",
    "# Feature Engineering (1/2)\n",
    "exped['sherpa_ratio'] = exped['tot_hired'] / exped['tot_members']\n",
    "exped['sherpa_ratio'] = np.where(exped['sherpa_ratio'] == np.inf, 0, exped['sherpa_ratio'])\n",
    "\n",
    "\n",
    "# Merge DataFrames\n",
    "df = exped.merge(member, on='exp_id', how = 'right')\n",
    "\n",
    "\n",
    "df.drop(columns=['summit_date', 'exp_id', 'bc_date', 'term_reason'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "col_num = []\n",
    "col_bool =[]\n",
    "col_object =[]\n",
    "\n",
    "for col in df:\n",
    "    if df[col].dtype == \"float64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == \"int64\":\n",
    "        col_num.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'bool':\n",
    "        col_bool.append(col)\n",
    "        \n",
    "    if df[col].dtype == 'object':\n",
    "        col_object.append(col)\n",
    "        \n",
    "col_bool.remove('summit_success')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop= 'first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, col_num),\n",
    "        ('cat', categorical_transformer, col_object)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X = df.drop(columns=['summit_success'])\n",
    "y = df.summit_success\n",
    "\n",
    "X_trans = clf.fit_transform(X)\n",
    "X_tr = X_trans.toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr, y, test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.82      0.83      2792\n",
      "        True       0.77      0.78      0.78      2123\n",
      "\n",
      "    accuracy                           0.81      4915\n",
      "   macro avg       0.80      0.80      0.80      4915\n",
      "weighted avg       0.81      0.81      0.81      4915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Traning\n",
    "from sklearn.metrics import classification_report\n",
    "boost = XGBClassifier()\n",
    "boost.fit(X_train, y_train)\n",
    "ypred = boost.predict(X_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "from data import Data\n",
    "df = Data().get_matching_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summit_date</th>\n",
       "      <th>exp_id</th>\n",
       "      <th>peak_id</th>\n",
       "      <th>host</th>\n",
       "      <th>leaders</th>\n",
       "      <th>bc_date</th>\n",
       "      <th>summit_days</th>\n",
       "      <th>tot_days</th>\n",
       "      <th>camps</th>\n",
       "      <th>rope</th>\n",
       "      <th>...</th>\n",
       "      <th>high_point</th>\n",
       "      <th>o2_used</th>\n",
       "      <th>death</th>\n",
       "      <th>death_type</th>\n",
       "      <th>death_height</th>\n",
       "      <th>death_class</th>\n",
       "      <th>summit_bid</th>\n",
       "      <th>summit_term</th>\n",
       "      <th>age</th>\n",
       "      <th>cumul_snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>TKRG10101</td>\n",
       "      <td>TKRG</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>David Gottlieb</td>\n",
       "      <td>2010-03-06</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6771</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Successful summit bid</td>\n",
       "      <td>Success</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>TKRG10101</td>\n",
       "      <td>TKRG</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>David Gottlieb</td>\n",
       "      <td>2010-03-06</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>No summit bid</td>\n",
       "      <td>No climbing</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>TKRG10101</td>\n",
       "      <td>TKRG</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>David Gottlieb</td>\n",
       "      <td>2010-03-06</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6771</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Successful summit bid</td>\n",
       "      <td>Success</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>AMAD10101</td>\n",
       "      <td>AMAD</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>Orial Ribas</td>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Aborted above high camp</td>\n",
       "      <td>Bad weather</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>AMAD10101</td>\n",
       "      <td>AMAD</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>Orial Ribas</td>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Aborted above high camp</td>\n",
       "      <td>Bad weather</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  summit_date     exp_id peak_id   host         leaders    bc_date  \\\n",
       "0  2010-03-12  TKRG10101    TKRG  Nepal  David Gottlieb 2010-03-06   \n",
       "1  2010-03-12  TKRG10101    TKRG  Nepal  David Gottlieb 2010-03-06   \n",
       "2  2010-03-12  TKRG10101    TKRG  Nepal  David Gottlieb 2010-03-06   \n",
       "6  2010-04-21  AMAD10101    AMAD  Nepal     Orial Ribas 2010-04-05   \n",
       "7  2010-04-21  AMAD10101    AMAD  Nepal     Orial Ribas 2010-04-05   \n",
       "\n",
       "   summit_days  tot_days  camps  rope  ...  high_point  o2_used  death  \\\n",
       "0            6         8      0     0  ...        6771    False  False   \n",
       "1            6         8      0     0  ...           0    False  False   \n",
       "2            6         8      0     0  ...        6771    False  False   \n",
       "6           16        17      0     0  ...        6500    False  False   \n",
       "7           16        17      0     0  ...        6500    False  False   \n",
       "\n",
       "    death_type  death_height  death_class               summit_bid  \\\n",
       "0  Unspecified             0  Unspecified    Successful summit bid   \n",
       "1  Unspecified             0  Unspecified            No summit bid   \n",
       "2  Unspecified             0  Unspecified    Successful summit bid   \n",
       "6  Unspecified             0  Unspecified  Aborted above high camp   \n",
       "7  Unspecified             0  Unspecified  Aborted above high camp   \n",
       "\n",
       "   summit_term   age  cumul_snow  \n",
       "0      Success  43.0         0.0  \n",
       "1  No climbing  39.0         0.0  \n",
       "2      Success  37.0         0.0  \n",
       "6  Bad weather  46.0         4.1  \n",
       "7  Bad weather  39.0         4.1  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from data import Data\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Import and clean data (importing csv into pandas)\n",
    "df = Data().get_matching_table()\n",
    "\n",
    "mylist = df.peak_id.unique()\n",
    "peak_list = pd.DataFrame({'peak' : mylist})\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "\n",
    "    html.H1(\"HimalayApp\", style={'text-align': 'center'}),\n",
    "\n",
    "    dcc.RangeSlider(\n",
    "        id='year_slider',\n",
    "        min=2010,\n",
    "        max=2020,\n",
    "        step=1,\n",
    "        value=[2010, 2020],\n",
    "        marks= {i : str(i) for i in range(2010, 2021)}),\n",
    "\n",
    "    html.Div(id='output_container', children=[]),\n",
    "    html.Br(),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown',\n",
    "        options=[{'label':i, 'value':i} for i in peak_list['peak']]),\n",
    "\n",
    "    html.Div(id='output', children=[]),\n",
    "    html.Br()])\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "# # Connect the Plotly graphs with Dash Components\n",
    "# @app.callback(\n",
    "#     [Output(component_id='output_container', component_property='children'),\n",
    "#      Output(component_id='output', component_property='children')],\n",
    "#     [Input(component_id='year_slider', component_property='value')])\n",
    "\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------------------\n",
    "__name__ == '__main__'\n",
    "app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
